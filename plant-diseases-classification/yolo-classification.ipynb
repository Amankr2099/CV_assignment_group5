{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone --depth 1 https://github.com/spMohanty/PlantVillage-Dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "!pip install ultralytics\n",
    "from ultralytics import YOLO  # For YOLOv11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define paths\n",
    "dataset_path = 'PlantVillage-Dataset/raw/color'\n",
    "\n",
    "# Get list of all images and their labels\n",
    "images = []\n",
    "labels = []\n",
    "class_names = os.listdir(dataset_path)\n",
    "class_to_idx = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "\n",
    "# Fix the total number of samples per class to 500\n",
    "fixed_samples_per_class = 500\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_path = os.path.join(dataset_path, class_name)\n",
    "    img_paths = [os.path.join(class_path, img_name) for img_name in os.listdir(class_path)]\n",
    "\n",
    "    # Randomly sample 500 images per class (or take all if fewer)\n",
    "    img_paths = random.sample(img_paths, min(len(img_paths), fixed_samples_per_class))\n",
    "\n",
    "    images.extend(img_paths)\n",
    "    labels.extend([class_to_idx[class_name]] * len(img_paths))\n",
    "\n",
    "# Split the dataset into training (60%), validation (20%), and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PlantVillageDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(self.image_paths[idx])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        image = cv2.resize(image, (224, 224))  # Resize to 224x224\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = PlantVillageDataset(X_train, y_train, transform=transform)\n",
    "val_dataset = PlantVillageDataset(X_val, y_val, transform=transform)\n",
    "test_dataset = PlantVillageDataset(X_test, y_test, transform=transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Train Samples: {len(train_dataset)}, Val Samples: {len(val_dataset)}, Test Samples: {len(test_dataset)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model_name, train_loader, val_loader, test_loader, num_classes, num_epochs=5):\n",
    "    # Load YOLO model (smallest version)\n",
    "    if model_name == 'YOLOv11':\n",
    "        model = YOLO('yolov11n.pt')  # Smallest version of YOLOv11\n",
    "    else:\n",
    "        raise ValueError(\"Model not supported\")\n",
    "\n",
    "    # Move model to GPU if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training loop\n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_acc = 100.0 * correct / total\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_acc = 100.0 * correct / total\n",
    "        val_losses.append(val_loss)\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.plot(train_accs, label='Training Accuracy')\n",
    "    plt.plot(val_accs, label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} Training and Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    y_true, y_scores = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_scores.extend(probs)\n",
    "\n",
    "    # Plot PR curves for top-N classes\n",
    "    y_true = np.array(y_true)\n",
    "    y_scores = np.array(y_scores)\n",
    "    top_n = 5\n",
    "    ap_scores = []\n",
    "\n",
    "    for class_idx in range(num_classes):\n",
    "        average_precision = average_precision_score(y_true == class_idx, y_scores[:, class_idx])\n",
    "        ap_scores.append((class_idx, average_precision))\n",
    "\n",
    "    top_classes = sorted(ap_scores, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for class_idx, average_precision in top_classes:\n",
    "        precision, recall, _ = precision_recall_curve(y_true == class_idx, y_scores[:, class_idx])\n",
    "        plt.plot(recall, precision, label=f'Class {class_idx} (AP={average_precision:.2f})')\n",
    "\n",
    "    plt.title(f'{model_name} Precision-Recall Curve (Top-{top_n} Classes)', fontsize=16)\n",
    "    plt.xlabel('Recall', fontsize=14)\n",
    "    plt.ylabel('Precision', fontsize=14)\n",
    "    plt.legend(loc='best', fontsize=12)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = 'YOLOv11'\n",
    "result = train_model(model, train_loader, val_loader, test_loader, num_classes=38, num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
